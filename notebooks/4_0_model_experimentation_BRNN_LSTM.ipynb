{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_0_model_experimentation_BRNN_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLqeQ2zISoxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gdown\n",
        "import os\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "# https://drive.google.com/file/d/1l_J0P9A_AD8d_rzZHJ5Fg8F4y1nGP_x3/view?usp=sharing\n",
        "\n",
        "url = f'https://drive.google.com/uc?id=1l_J0P9A_AD8d_rzZHJ5Fg8F4y1nGP_x3'\n",
        "filename = 'dataset.csv'\n",
        "if not os.path.exists(filename):\n",
        "    gdown.download(url, filename, quiet=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8lpxHGCTRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvhCE49JTUA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['emotion', 'text']\n",
        "\n",
        "df = pd.read_csv(filename, names=columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSSP9JxBTg9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xraw = df['text'].values\n",
        "yraw = df['emotion'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujQ3AdDST8Ow",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEIB57-UU8K4",
        "colab_type": "code",
        "outputId": "5ca212ca-6bce-48dc-8771-60f269329375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mna_HRCvZThv",
        "colab_type": "code",
        "outputId": "9d693dbd-5667-4101-8a71-98779286cd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!python -m pip install -U symspellpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: symspellpy in /usr/local/lib/python3.6/dist-packages (6.5.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0pSRbSawKa",
        "colab_type": "code",
        "outputId": "33eea5f9-1473-440d-8631-2a33f629fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "text_raw = df['text'].values\n",
        "print(text_raw[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On days when I feel close to my partner and other friends.   \n",
            "When I feel at peace with myself and also experience a close  \n",
            "contact with people whom I regard greatly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3U5TXZSm_uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell()\n",
        "\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "\n",
        "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
        "\n",
        "spell = lambda term: ' '.join([sym_spell.lookup(t, Verbosity.CLOSEST, \n",
        "                                      max_edit_distance=2, include_unknown=True)[0].term for t in term.split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUUMijzTul2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "process_text = lambda t: word_tokenize(t.lower()) if type(t) is str else []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_oit70nbDN4",
        "colab_type": "code",
        "outputId": "4c826cb1-500e-469a-915f-baf836b7255b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_prep = list(map(process_text, text_raw))\n",
        "' | '.join(text_prep[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'on | days | when | i | feel | close | to | my | partner | and | other | friends | . | when | i | feel | at | peace | with | myself | and | also | experience | a | close | contact | with | people | whom | i | regard | greatly | .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6Iwo48jFHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_text  = df['text'].str.cat()\n",
        "all_text_prep = process_text(all_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVsEgIZTkRF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(all_text_prep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Un9n0lLkdaA",
        "colab_type": "code",
        "outputId": "321488ce-db6b-4e92-878e-4d8b1150add0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "word_freq.most_common()[-10:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('classmate.when', 1),\n",
              " ('baptism', 1),\n",
              " ('pepole', 1),\n",
              " ('baptised', 1),\n",
              " ('deepened.when', 1),\n",
              " ('gym', 1),\n",
              " ('stack', 1),\n",
              " ('questioning', 1),\n",
              " ('inserted', 1),\n",
              " ('randomly', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_1Nf5Bmuiyb",
        "colab_type": "code",
        "outputId": "23fd8a56-d23f-4d32-dbda-1724af46b5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = list(word_freq.keys())\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnRdHYEocHUT",
        "colab_type": "text"
      },
      "source": [
        "### GLOVE pretrained word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f_9cDzbSpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNhwJSTwcOmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xoLbwAAhTjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lines = []\n",
        "\n",
        "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
        "#     for l in f:\n",
        "#         line_decode = l.decode(encoding='utf-8')\n",
        "#         line = line_decode.lower().split()\n",
        "\n",
        "#         if line[0] in word_freq:\n",
        "#             lines.append(line_decode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBi8XD6sxbn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lines[0]\n",
        "# len(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEapHaz8xQ3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vecfilename = 'relevant_word2vec.txt'\n",
        "\n",
        "# with open(word2vecfilename, 'w') as wf:\n",
        "#     wf.write(\"\".join(lines))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BURclwT6j9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vecfilename = 'relevant_word2vec.txt'\n",
        "\n",
        "# https://drive.google.com/file/d/1E2FCguEoggAVak1dCXksXlfq7ruOiFU1/view?usp=sharing\n",
        "w2vurl = f'https://drive.google.com/uc?id=1E2FCguEoggAVak1dCXksXlfq7ruOiFU1'\n",
        "\n",
        "if not os.path.exists(word2vecfilename):\n",
        "    gdown.download(w2vurl, word2vecfilename, quiet=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSYfO4-Ex2rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vec = {}\n",
        "with open(word2vecfilename) as fr:\n",
        "    for l in fr:\n",
        "        line = l.split()\n",
        "        word = line[0]\n",
        "        wordvec = np.array(line[1:], dtype=np.float64)\n",
        "        word2vec[word] = wordvec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkWHzoeW7jFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(18)\n",
        "word2vec['UNK'] = np.random.randn(300, 1)\n",
        "# word2vec['UNK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EmsHbc9VdNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# processed_text = process_text(text)\n",
        "# processed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpUcA0zp0yyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_input(inputs):\n",
        "    return [\n",
        "         np.array([word2vec[tk].flatten() for tk in process_text(text) if tk in word2vec])\n",
        "         for text in inputs\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6SXxZK9IER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xp = process_input(list(text_raw))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m6uAj-7aeD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = list(set(yraw))\n",
        "\n",
        "yci = np.array([classes.index(c) for c in yraw], dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8vw0thw_M0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "enc.fit(yraw.reshape(-1, 1))\n",
        "\n",
        "yenc = enc.transform(yraw.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvrSwEp-l2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29oEJEQMkNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xenc = np.array(Xp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDPWCXhY_CgX",
        "colab_type": "code",
        "outputId": "4eda2e8d-1c69-4d9a-f1fd-790afb08d490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Xenc, yci, test_size=0.2)\n",
        "\n",
        "print(len(X_train), len(X_test), y_train.shape, y_test.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5956 1490 (5956,) (1490,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW6-T0UnNEEA",
        "colab_type": "code",
        "outputId": "5c642c58-0f93-4d91-ae89-88f9840ff387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK0AzAj2cfFJ",
        "colab_type": "text"
      },
      "source": [
        "### Bidirectional LSTM Encoder-Decoder architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g188G_vBLstV",
        "colab_type": "code",
        "outputId": "07aae071-c197-4db6-af05-9d076ac8e375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'device: {device}')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzslBhwDL2gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = torch.tensor(X_train, device=device)\n",
        "# y_train = torch.tensor(y_train, device=device)\n",
        "\n",
        "# X_test = torch.tensor(X_test, device=device)\n",
        "# y_test = torch.tensor(y_test, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPi1gfaci8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_class, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=300, hidden_size=self.hidden_size)\n",
        "\n",
        "    def forward(self, inp, hidden_state):\n",
        "        # print(inp.shape)\n",
        "        # print(f'forward: {inp}')\n",
        "        return self.lstm(inp.view((1, 1, -1)), hidden_state)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_class, hidden_size):\n",
        "        super().__init__()\n",
        "        # self.lin_layer = nn.Linear(hidden_size, 512)\n",
        "        self.out_layer = nn.Linear(hidden_size, n_class)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # out1 = torch.tanh(self.lin_layer(inp))\n",
        "        return F.log_softmax(self.out_layer(inp).squeeze(), dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVxBJk1nDbQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(7, 1024).to(device)\n",
        "decoder = Decoder(7, 1024).to(device)\n",
        "\n",
        "enc_optim = optim.Adam(encoder.parameters())\n",
        "dec_optim = optim.Adam(decoder.parameters())\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WalkXlvDDpzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X_i, y_i, encoder, decoder, enc_optim, dec_optim, criterion):\n",
        "    hidden, cell = encoder.init_hidden()\n",
        "\n",
        "    enc_optim.zero_grad()\n",
        "    dec_optim.zero_grad()\n",
        "\n",
        "    X_i = torch.tensor(X_i, dtype=torch.float32, device=device)\n",
        "    y_i = torch.tensor(y_i, dtype=torch.long, device=device).view(1)\n",
        "    # y_i = int(y_i)\n",
        "\n",
        "    n_len = X_i.size(0)\n",
        "    # print(f'Shape of X_i: {X_i.shape}, {X_i.dtype}')\n",
        "    # print(f'Shape of y_i: {y_i.shape}, {y_i.dtype}')\n",
        "\n",
        "    for ei in range(n_len):\n",
        "        _, (hidden, cell) = encoder(X_i[ei], (hidden, cell))\n",
        "\n",
        "    # print(f'hidden: {hidden}, {type(hidden)}')\n",
        "\n",
        "    decoder_output = decoder(hidden).squeeze()\n",
        "    # print(f'decoder output: {decoder_output}, {decoder_output.shape}')\n",
        "    # print(f'y_i: {y_i}, {y_i.shape}')\n",
        "\n",
        "    loss = criterion(decoder_output.view(1, 7), y_i)\n",
        "    # print(f'Loss: {loss}')\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    enc_optim.step()\n",
        "    dec_optim.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtm_97tKnSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_iters(X, y, n_epochs, encoder, decoder, enc_optim, dec_optim, criterion):\n",
        "    for i in range(n_epochs):\n",
        "        num_X = len(X)\n",
        "\n",
        "        loss = 0\n",
        "        for xi in range(num_X):\n",
        "            if xi == (num_X - 1):\n",
        "                torch.save(encoder.state_dict(), './encoder.tm')\n",
        "                torch.save(decoder.state_dict(), './decoder.tm')\n",
        "                print(f'Training data: {xi}/{num_X}', end='\\n')\n",
        "                # training_accuracy = get_accuracy(X_train, y_train, encoder, decoder)\n",
        "                testing_accuracy = get_accuracy(X_test, y_test, encoder, decoder)\n",
        "\n",
        "                print(f'Testing accuracy: {testing_accuracy:.4f}')\n",
        "            loss += train(X[xi], y[xi], encoder, decoder, enc_optim, dec_optim, criterion)\n",
        "\n",
        "        loss /= num_X\n",
        "        print(f'Epoch: {i}, Loss: {loss:.5f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x5oFLteMY6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, encoder, decoder):\n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "        X_len = X.size(0)\n",
        "\n",
        "        hidden, cell = encoder.init_hidden()\n",
        "\n",
        "        for ei in range(X_len):\n",
        "            _, (hidden, cell) = encoder(X[ei], (hidden, cell))\n",
        "\n",
        "        decoder_output = decoder(hidden).squeeze()\n",
        "\n",
        "        return decoder_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E33fcR9WrsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def get_accuracy(X, y, encoder, decoder):\n",
        "    y_pred = [np.argmax(predict(Xi, encoder, decoder).cpu()) for Xi in X]\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnKzfSnp93Uo",
        "colab_type": "code",
        "outputId": "fa510df1-0658-4940-8060-236c6e8f1b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "train_iters(X_train, y_train, 4000, encoder, decoder, enc_optim, dec_optim, criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5785\n",
            "Epoch: 0, Loss: 1.41183\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5933\n",
            "Epoch: 1, Loss: 0.95683\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5919\n",
            "Epoch: 2, Loss: 0.65850\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5966\n",
            "Epoch: 3, Loss: 0.36715\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5792\n",
            "Epoch: 4, Loss: 0.20456\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5866\n",
            "Epoch: 5, Loss: 0.12315\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5872\n",
            "Epoch: 6, Loss: 0.10360\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5859\n",
            "Epoch: 7, Loss: 0.08695\n",
            "Training data: 5955/5956\n",
            "Testing accuracy: 0.5852\n",
            "Epoch: 8, Loss: 0.08023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvh25P0HU1cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = np.array([np.argmax(predict(xi, encoder, decoder).cpu()) for xi in X_train])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csJ0NAqdQFJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_train, y_train_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niOFkLuIPXqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_test_pred = np.array([np.argmax(predict(xi, encoder, decoder).cpu()) for xi in X_test])\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukqkx930aFLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}