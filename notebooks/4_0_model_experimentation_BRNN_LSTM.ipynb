{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.0.base-model-experimentation-BRNN-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLqeQ2zISoxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gdown\n",
        "import os\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "# https://drive.google.com/file/d/1l_J0P9A_AD8d_rzZHJ5Fg8F4y1nGP_x3/view?usp=sharing\n",
        "\n",
        "url = f'https://drive.google.com/uc?id=1l_J0P9A_AD8d_rzZHJ5Fg8F4y1nGP_x3'\n",
        "filename = 'dataset.csv'\n",
        "if not os.path.exists(filename):\n",
        "    gdown.download(url, filename, quiet=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8lpxHGCTRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvhCE49JTUA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['emotion', 'text']\n",
        "\n",
        "df = pd.read_csv(filename, names=columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSSP9JxBTg9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xraw = df['text'].values\n",
        "yraw = df['emotion'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujQ3AdDST8Ow",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEIB57-UU8K4",
        "colab_type": "code",
        "outputId": "824ae9be-940f-4c87-ef4f-df70a50aa5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mna_HRCvZThv",
        "colab_type": "code",
        "outputId": "4b645723-a949-44d9-fed8-4226568ef6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!python -m pip install -U symspellpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/0b/2daa14bf1ed649fff0d072b2e51ae98d8b45cae6cf8fdda41be01ce6c289/symspellpy-6.5.2-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0pSRbSawKa",
        "colab_type": "code",
        "outputId": "b77ca602-a929-41de-91b5-a8e5b7cd858e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "text_raw = df['text'].values\n",
        "print(text_raw[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On days when I feel close to my partner and other friends.   \n",
            "When I feel at peace with myself and also experience a close  \n",
            "contact with people whom I regard greatly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3U5TXZSm_uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell()\n",
        "\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "\n",
        "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
        "\n",
        "spell = lambda term: ' '.join([sym_spell.lookup(t, Verbosity.CLOSEST, \n",
        "                                      max_edit_distance=2, include_unknown=True)[0].term for t in term.split()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUUMijzTul2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "process_text = lambda t: word_tokenize(t.lower()) if type(t) is str else []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_oit70nbDN4",
        "colab_type": "code",
        "outputId": "2ae336a5-6e4c-44c6-c714-6258b25c92cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_prep = list(map(process_text, text_raws))\n",
        "' | '.join(text_prep[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in | days | when | a | feel | close | to | my | partner | and | other | friends | when | a | feel | at | peace | with | myself | and | also | experience | a | close | contact | with | people | whom | a | regard | greatly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6Iwo48jFHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_text  = df['text'].str.cat()\n",
        "all_text_prep = process_text(all_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVsEgIZTkRF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(all_text_prep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Un9n0lLkdaA",
        "colab_type": "code",
        "outputId": "235459e6-2f12-4f80-bc21-c9d454689bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word_freq.most_common()[-100:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tears.when', 1),\n",
              " ('others.during', 1),\n",
              " ('persoon', 1),\n",
              " ('ashamed.our', 1),\n",
              " ('organizor', 1),\n",
              " ('ponder', 1),\n",
              " ('apologetic', 1),\n",
              " ('afterwards.it', 1),\n",
              " ('mr.w', 1),\n",
              " ('p.m.the', 1),\n",
              " ('die.one', 1),\n",
              " ('sunned', 1),\n",
              " ('snatched', 1),\n",
              " ('starteed', 1),\n",
              " ('freely.when', 1),\n",
              " ('before.my', 1),\n",
              " ('favour.on', 1),\n",
              " ('zip', 1),\n",
              " ('happened.one', 1),\n",
              " ('thirsty', 1),\n",
              " ('fetched', 1),\n",
              " ('thermos', 1),\n",
              " ('pour', 1),\n",
              " ('flurry', 1),\n",
              " ('phillipines', 1),\n",
              " ('dim', 1),\n",
              " ('dawn.i', 1),\n",
              " ('didcovered', 1),\n",
              " ('thay', 1),\n",
              " ('out.a', 1),\n",
              " ('exam.once', 1),\n",
              " ('athletic', 1),\n",
              " ('flaws', 1),\n",
              " ('muttered', 1),\n",
              " ('day.my', 1),\n",
              " ('scissors', 1),\n",
              " ('fastidious', 1),\n",
              " ('intolerable.i', 1),\n",
              " ('p3', 1),\n",
              " ('admited', 1),\n",
              " ('hong', 1),\n",
              " ('kong', 1),\n",
              " ('number.one', 1),\n",
              " ('ghosts.when', 1),\n",
              " ('team-mate', 1),\n",
              " ('disgusting.when', 1),\n",
              " ('riot', 1),\n",
              " ('replied', 1),\n",
              " ('best.i', 1),\n",
              " ('mates.i', 1),\n",
              " ('flatter', 1),\n",
              " ('sex.during', 1),\n",
              " ('organizors', 1),\n",
              " ('bright', 1),\n",
              " ('attendants', 1),\n",
              " ('prefects', 1),\n",
              " ('structure', 1),\n",
              " ('consult', 1),\n",
              " ('dampened', 1),\n",
              " ('enthusiasm', 1),\n",
              " ('leaders.one', 1),\n",
              " ('estimate', 1),\n",
              " ('revision', 1),\n",
              " ('poorly.once', 1),\n",
              " ('monetary', 1),\n",
              " ('civil', 1),\n",
              " ('goose', 1),\n",
              " ('this.during', 1),\n",
              " ('part.once', 1),\n",
              " ('tai', 1),\n",
              " ('pectoral', 1),\n",
              " ('girdle', 1),\n",
              " ('examination.after', 1),\n",
              " ('chyne', 1),\n",
              " ('freely', 1),\n",
              " ('sincere.at', 1),\n",
              " ('noon', 1),\n",
              " ('boxes', 1),\n",
              " ('accident.the', 1),\n",
              " ('doings', 1),\n",
              " ('cv', 1),\n",
              " ('mainland', 1),\n",
              " ('sad.during', 1),\n",
              " ('britain', 1),\n",
              " ('accquainted', 1),\n",
              " ('b.b.q', 1),\n",
              " ('departing', 1),\n",
              " ('mahjong', 1),\n",
              " ('decency', 1),\n",
              " ('half-heartedly', 1),\n",
              " ('classmate.when', 1),\n",
              " ('baptism', 1),\n",
              " ('pepole', 1),\n",
              " ('baptised', 1),\n",
              " ('deepened.when', 1),\n",
              " ('gym', 1),\n",
              " ('stack', 1),\n",
              " ('questioning', 1),\n",
              " ('inserted', 1),\n",
              " ('randomly', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_1Nf5Bmuiyb",
        "colab_type": "code",
        "outputId": "a8d06a19-34bf-409f-befd-abf805a9516c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = list(word_freq.keys())\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnRdHYEocHUT",
        "colab_type": "text"
      },
      "source": [
        "### GLOVE pretrained word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f_9cDzbSpg",
        "colab_type": "code",
        "outputId": "9273690c-11a8-4e86-b34b-032ac4159656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 14:36:28--  http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip [following]\n",
            "--2020-05-13 14:36:28--  https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.42B.300d.zip [following]\n",
            "--2020-05-13 14:36:28--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877802108 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  1.89MB/s    in 14m 39s \n",
            "\n",
            "2020-05-13 14:51:08 (2.04 MB/s) - ‘glove.42B.300d.zip’ saved [1877802108/1877802108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNhwJSTwcOmy",
        "colab_type": "code",
        "outputId": "8be16dd5-993e-4f7b-86dc-683ca9b92b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# !unzip glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xoLbwAAhTjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lines = []\n",
        "\n",
        "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
        "#     for l in f:\n",
        "#         line_decode = l.decode(encoding='utf-8')\n",
        "#         line = line_decode.lower().split()\n",
        "\n",
        "#         if line[0] in word_freq:\n",
        "#             lines.append(line_decode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBi8XD6sxbn7",
        "colab_type": "code",
        "outputId": "123e400e-f12a-4ac6-8f18-0eaccb4fcc31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# lines[0]\n",
        "# len(lines)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEapHaz8xQ3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vecfilename = 'relevant_word2vec.txt'\n",
        "\n",
        "# with open(word2vecfilename, 'w') as wf:\n",
        "#     wf.write(\"\".join(lines))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BURclwT6j9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vecfilename = 'relevant_word2vec.txt'\n",
        "\n",
        "# https://drive.google.com/file/d/1E2FCguEoggAVak1dCXksXlfq7ruOiFU1/view?usp=sharing\n",
        "w2vurl = f'https://drive.google.com/uc?id=1E2FCguEoggAVak1dCXksXlfq7ruOiFU1'\n",
        "\n",
        "if not os.path.exists(word2vecfilename):\n",
        "    gdown.download(w2vurl, word2vecfilename, quiet=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSYfO4-Ex2rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vec = {}\n",
        "with open(word2vecfilename) as fr:\n",
        "    for l in fr:\n",
        "        line = l.split()\n",
        "        word = line[0]\n",
        "        wordvec = np.array(line[1:], dtype=np.float64)\n",
        "        word2vec[word] = wordvec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkWHzoeW7jFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(18)\n",
        "word2vec['UNK'] = np.random.randn(300, 1)\n",
        "# word2vec['UNK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpUcA0zp0yyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_input(inputs):\n",
        "    return [\n",
        "         np.array([\n",
        "          word2vec[tk].flatten() if tk in word2vec else word2vec['UNK'].flatten() for tk in process_text(text)\n",
        "          ])\n",
        "         for text in inputs\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6SXxZK9IER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xp = process_input(list(text_raw))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m6uAj-7aeD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = list(set(yraw))\n",
        "\n",
        "yci = np.array([classes.index(c) for c in yraw], dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8vw0thw_M0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "enc.fit(yraw.reshape(-1, 1))\n",
        "\n",
        "yenc = enc.transform(yraw.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvrSwEp-l2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29oEJEQMkNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xenc = np.array(Xp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDPWCXhY_CgX",
        "colab_type": "code",
        "outputId": "50a986b2-c18a-46a7-f1b1-b6a52afdd8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Xenc, yci)\n",
        "\n",
        "print(len(X_train), len(X_test), y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5584 1862 (5584,) (1862,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW6-T0UnNEEA",
        "colab_type": "code",
        "outputId": "9790f5ee-844e-4e2d-a911-07407ab3e5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK0AzAj2cfFJ",
        "colab_type": "text"
      },
      "source": [
        "### Bidirectional LSTM Encoder-Decoder architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g188G_vBLstV",
        "colab_type": "code",
        "outputId": "b8d4c234-de77-4541-ba4b-a57c7942afad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'device: {device}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzslBhwDL2gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = torch.tensor(X_train, device=device)\n",
        "# y_train = torch.tensor(y_train, device=device)\n",
        "\n",
        "# X_test = torch.tensor(X_test, device=device)\n",
        "# y_test = torch.tensor(y_test, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWPi1gfaci8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_class, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=300, hidden_size=self.hidden_size)\n",
        "\n",
        "    def forward(self, inp, hidden_state):\n",
        "        print(inp.shape)\n",
        "        # print(f'forward: {inp}')\n",
        "        return self.lstm(inp.view((1, 1, -1)), hidden_state)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device).double(),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device).double())\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_class, hidden_size):\n",
        "        super().__init__()\n",
        "        self.lin_layer = nn.Linear(hidden_size, 512)\n",
        "        self.out_layer = nn.Linear(512, n_class)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out1 = F.tanh(self.lin_layer(inp))\n",
        "        return F.softmax(self.out_layer(out1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVxBJk1nDbQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(7, 1024).to(device)\n",
        "decoder = Decoder(7, 1024).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE6npeikIfpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_optim = optim.Adam(encoder.parameters())\n",
        "dec_optim = optim.Adam(decoder.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WalkXlvDDpzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X_i, y_i, encoder, decoder, enc_optim, dec_optim):\n",
        "    hidden = encoder.init_hidden()\n",
        "\n",
        "    enc_optim.zero_grad()\n",
        "    dec_optim.zero_grad()\n",
        "\n",
        "    X_i = torch.tensor(X_i, device=device).double()\n",
        "    y_i = torch.tensor(y_i, device=device).double()\n",
        "\n",
        "    n_len = X_i.size(0)\n",
        "    print(f'Shape of X_i: {X_i.shape}, {X_i.dtype}')\n",
        "    print(f'Shape of y_i: {y_i.shape}, {y_i.dtype}')\n",
        "\n",
        "    for ei in range(n_len):\n",
        "        _, hidden = encoder(X_i[ei], hidden)\n",
        "        print(type(hidden))\n",
        "\n",
        "    print(f'hidden: {hidden}, {type(hidden)}')\n",
        "\n",
        "    decoder_output = decoder(torch.cat(hidde, dim=0))\n",
        "\n",
        "    loss = nn.NLLLoss()(decoder_output, y_i)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    enc_optim.step()\n",
        "    dec_optim.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtm_97tKnSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_iters(X, y, n_epochs, encoder, decoder, enc_optim, dec_optim):\n",
        "    for i in range(n_epochs):\n",
        "        num_X = len(X)\n",
        "\n",
        "        loss = 0\n",
        "        for xi in range(num_X):\n",
        "            loss += train(X[xi], y[xi], encoder, decoder, enc_optim, dec_optim)\n",
        "\n",
        "        print(f'Epoch: {i}, Loss: {loss:.5f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_vTai8Le_1",
        "colab_type": "code",
        "outputId": "a7dc0771-414d-4176-9287-438d5aa4fb7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        }
      },
      "source": [
        "train_iters(X_train, y_train, 10, encoder, decoder, enc_optim, dec_optim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_i: torch.Size([11, 300]), torch.float64\n",
            "Shape of y_i: torch.Size([]), torch.float64\n",
            "torch.Size([300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-419-f939a5552932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_optim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-418-d90be9922d31>\u001b[0m in \u001b[0;36mtrain_iters\u001b[0;34m(X, y, n_epochs, encoder, decoder, enc_optim, dec_optim)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_optim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {i}, Loss: {loss:.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-417-8ab9fe3c1755>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_i, y_i, encoder, decoder, enc_optim, dec_optim)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-414-e24a339f9da0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hidden_state)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(f'forward: {inp}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxrIttvUMx9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}